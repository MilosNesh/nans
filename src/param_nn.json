{"activation": "relu", "hidden_layer_sizes": [100, 50], "learning_rate_init": 0.001, "max_iter": 1000}